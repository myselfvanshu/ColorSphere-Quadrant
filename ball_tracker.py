# -*- coding: utf-8 -*-
"""AI role1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-twXtvs9zxJmEs-_b3suQbDz6c-r0vDY
"""

pip install opencv-python-headless numpy pandas scikit-learn

import cv2
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans

def load_video(video_path):
    return cv2.VideoCapture(video_path)

def get_quadrants(frame_width, frame_height):
    half_width = frame_width // 2
    half_height = frame_height // 2
    quadrants = {
        1: ((half_width, half_height), (frame_width, frame_height)),
        2: ((0, half_height), (half_width, frame_height)),
        3: ((0, 0), (half_width, half_height)),
        4: ((half_width, 0), (frame_width, half_height))
    }
    return quadrants

def detect_balls(frame, n_colors=4):
    data = frame.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors)
    kmeans.fit(data)
    unique_colors = kmeans.cluster_centers_.astype(int)
    masks = {}
    for i, color in enumerate(unique_colors):
        lower_bound = np.maximum(color - 20, 0)
        upper_bound = np.minimum(color + 20, 255)
        mask = cv2.inRange(frame, lower_bound, upper_bound)
        masks[f"Color_{i+1}"] = mask
    return masks, unique_colors

def track_balls(masks):
    ball_positions = {}
    for color, mask in masks.items():
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            c = max(contours, key=cv2.contourArea)
            ((x, y), radius) = cv2.minEnclosingCircle(c)
            if radius > 10:  # filter out small contours
                ball_positions[color] = (int(x), int(y))
    return ball_positions

def detect_events(ball_positions, prev_positions, quadrants, frame_time):
    events = []
    for color, (x, y) in ball_positions.items():
        for quadrant_num, ((x1, y1), (x2, y2)) in quadrants.items():
            if x1 < x < x2 and y1 < y < y2:
                if color in prev_positions:
                    px, py = prev_positions[color]
                    if not (x1 < px < x2 and y1 < py < y2):
                        events.append((frame_time, quadrant_num, color, "Entry"))
                else:
                    events.append((frame_time, quadrant_num, color, "Entry"))
    for color, (px, py) in prev_positions.items():
        if color not in ball_positions:
            continue
        x, y = ball_positions[color]
        for quadrant_num, ((x1, y1), (x2, y2)) in quadrants.items():
            if x1 < px < x2 and y1 < py < y2 and not (x1 < x < x2 and y1 < y < y2):
                events.append((frame_time, quadrant_num, color, "Exit"))
    return events

def record_events(events, output_file):
    df = pd.DataFrame(events, columns=["Time", "Quadrant Number", "Ball Colour", "Type"])
    df.to_csv(output_file, index=False)

def annotate_frame(frame, events):
    for event in events:
        time, quadrant, color, event_type = event
        cv2.putText(frame, f"{event_type} {color}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"Time: {time:.2f}s", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    return frame

def process_video(video_path, output_video_path, output_file):
    cap = load_video(video_path)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    quadrants = get_quadrants(frame_width, frame_height)
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))

    events = []
    prev_positions = {}

    for frame_idx in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break
        frame_time = frame_idx / frame_rate
        masks, unique_colors = detect_balls(frame)
        ball_positions = track_balls(masks)
        frame_events = detect_events(ball_positions, prev_positions, quadrants, frame_time)
        events.extend(frame_events)
        annotated_frame = annotate_frame(frame, frame_events)
        out.write(annotated_frame)
        prev_positions = ball_positions

    cap.release()
    out.release()
    record_events(events, output_file)

process_video('/content/AI Assignment video.mp4', 'output_video.avi', 'events.txt')